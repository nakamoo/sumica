{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib nbagg\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(\"..\")\n",
    "os.chdir(\"/home/nakamura/HAI/main_server/hai\")\n",
    "\n",
    "import coloredlogs, logging\n",
    "logger = logging.getLogger(__name__)\n",
    "coloredlogs.install(level='CRITICAL', logger=logger)\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from bson.objectid import ObjectId\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from notebooks.utils.utils import visualize, display_latest_image, display_image, print_time, strtime_to_epoch, epoch_to_strtime, UpdateDist, display_two_images\n",
    "from controllers.actionrec import ActionRecognition\n",
    "from controllers.dbreader.hue_koki_dbreader import HueDBReader, pair_images, extract_color, ExprHueDBReader\n",
    "from controllers.dbreader.opedbreader import OperationDBReader, collect_img_tv, collect_img_music\n",
    "from controllers.dbreader.imagereader import ImageReader\n",
    "from controllers.vectorizer.posennvectorizer import NNVectorizer, ActVectorizer\n",
    "from controllers.vectorizer.person2vec import Person2Vec\n",
    "\n",
    "mongo = MongoClient('localhost', 20202).hai\n",
    "\n",
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "app.config.from_pyfile(filename=\"application.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = strtime_to_epoch(\"2017-12-17 14:00:00\")\n",
    "end = strtime_to_epoch(\"2017-12-17 15:05:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imreader = ImageReader()\n",
    "X, y = imreader.read_db('koki', start, end, ['webcam0', 'webcam1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for yi in y:\n",
    "    if yi not in labels:\n",
    "        labels.append(yi)\n",
    "        \n",
    "new_y = []\n",
    "for yi in y:\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == yi:\n",
    "            new_y.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'bri': 254, 'hue': 14910, 'on': True, 'sat': 144}, 'stop_youtube', 'off'),\n",
       " ({'bri': 254, 'hue': 14910, 'on': True, 'sat': 144}, 'play_youtube', 'off'),\n",
       " ({'bri': 254, 'hue': 14910, 'on': True, 'sat': 144}, 'stop_youtube', 'on'),\n",
       " ({'bri': 254, 'hue': 2049, 'on': True, 'sat': 0}, 'stop_youtube', 'off'),\n",
       " ({'bri': 254, 'hue': 2049, 'on': True, 'sat': 0}, 'play_youtube', 'off'),\n",
       " ({'on': False}, 'play_youtube', 'off'),\n",
       " ({'on': False}, 'stop_youtube', 'off'),\n",
       " ({'bri': 254, 'hue': 11527, 'on': True, 'sat': 254}, 'play_youtube', 'off')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamura/.pyenv/versions/anaconda3-4.4.0/envs/detection_server/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, new_y, train_size=0.6, random_state=1)\n",
    "person2vectorizer = Person2Vec()\n",
    "pose_arr_train, act_arr_train, meta = person2vectorizer.vectorize(X_train, get_meta=True)\n",
    "pose_arr_val, act_arr_val, meta = person2vectorizer.vectorize(X_val, get_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85345997286295794"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "# clf = linear_model.SGDClassifier(loss='log')\n",
    "pipe = Pipeline([\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=50)),\n",
    "            (\"clf\", clf)\n",
    "    ])\n",
    "# cross_validation.cross_val_score(pipe, nn_mat_val, y_val, cv=5)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_arr, y_arr, train_size=0.6, random_state=1)\n",
    "pipe.fit(pose_arr_train, y_train)\n",
    "pipe.score(pose_arr_val, y_val)\n",
    "# y_predicted = pipe.predict(jk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88195386702849388"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "# clf = linear_model.SGDClassifier(loss='log')\n",
    "pipe = Pipeline([\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=50)),\n",
    "            (\"clf\", clf)\n",
    "    ])\n",
    "pipe.fit(act_arr_train, y_train)\n",
    "pipe.score(act_arr_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
